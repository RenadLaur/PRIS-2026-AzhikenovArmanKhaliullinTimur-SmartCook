import streamlit as st

try:
    from .knowledge_graph import load_graph
    from .logic import process_text_message
    from .nlp import get_spacy_status
except ImportError:
    from knowledge_graph import load_graph
    from logic import process_text_message
    from nlp import get_spacy_status


st.set_page_config(page_title="SmartCook Chat", page_icon="ü§ñ")
st.title("AI Assistant")
st.write("–°–ø—Ä–æ—Å–∏—Ç–µ —Ç–µ—Ä–º–∏–Ω –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (—Ä–µ—Ü–µ–ø—Ç, –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç –∏–ª–∏ –∞–ª–ª–µ—Ä–≥–µ–Ω).")


@st.cache_resource
def get_data_source():
    return load_graph()


def _compact(text):
    return " ".join(str(text).split())


data_source = None
data_source_error = None
try:
    data_source = get_data_source()
except Exception as exc:  # pragma: no cover - UI safeguard
    data_source_error = str(exc)

spacy_status = get_spacy_status()

if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç SmartCook. –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–∞, –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞ –∏–ª–∏ –∞–ª–ª–µ—Ä–≥–µ–Ω–∞.",
        }
    ]

if "query_history" not in st.session_state:
    st.session_state.query_history = []

with st.sidebar:
    st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    if st.button("–û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", use_container_width=True):
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "–ß–∞—Ç –æ—á–∏—â–µ–Ω. –í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–µ—Ü–µ–ø—Ç–∞, –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–∞ –∏–ª–∏ –∞–ª–ª–µ—Ä–≥–µ–Ω–∞.",
            }
        ]
        st.session_state.query_history = []
        st.rerun()

    st.header("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    if st.session_state.query_history:
        for idx, query in enumerate(st.session_state.query_history, start=1):
            st.write(f"{idx}. {query}")
    else:
        st.caption("–ü–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤")

    st.header("NLP –°—Ç–∞—Ç—É—Å")
    if not spacy_status["spacy_installed"]:
        st.error("spaCy –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ç–µ–∫—É—â–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏.")
    elif not spacy_status["model_found"]:
        st.warning("spaCy —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –Ω–æ –º–æ–¥–µ–ª—å (`ru_core_news_sm`) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    else:
        st.success("spaCy –∏ –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω—ã.")

    st.caption(f"Python: {spacy_status['python_executable']}")
    st.caption("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –∑–∞–ø—É—Å–∫: `.venv/bin/streamlit run src/main.py`")

if data_source_error:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {data_source_error}")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if user_input := st.chat_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å..."):
    clean_input = user_input.strip()
    if clean_input:
        st.session_state.query_history.append(clean_input)

    st.session_state.messages.append({"role": "user", "content": _compact(user_input)})
    with st.chat_message("user"):
        st.write(_compact(user_input))

    if data_source is None:
        bot_response = "–û—à–∏–±–∫–∞: –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Å–æ–ª—å —Å–µ—Ä–≤–µ—Ä–∞."
    else:
        try:
            bot_response = process_text_message(clean_input, data_source)
        except Exception as exc:  # pragma: no cover - UI safeguard
            bot_response = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {exc}"

    compact_response = _compact(bot_response)
    st.session_state.messages.append({"role": "assistant", "content": compact_response})
    with st.chat_message("assistant"):
        st.write(compact_response)
